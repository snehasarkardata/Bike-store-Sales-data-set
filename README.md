# Bike-store-Sales-data-set
A database schema for a fictional bike store
sales-Dataset
We have selected Sales Data from sales datasets. This dataset includes about 40,000 records and 15 attributes. Each record corresponds to a customer information like (gender, education, house Value, age, region, fam income, region, marriage, children, occupation, car probability, house own, flag (whether the customer purchased the target productor not) and online (whether the consumer had online shopping experience or not). This dataset provide helps to organizations to better understand their customer’s needs and makes it easier for organizations to modify products according to the specific needs, behaviors, and interests of customers. When organizations satisfy customers specific needs according to their demands it helps companies to increase there productive of different products in the entire market and helps to gain more and more profit. Because companies’ whole profit and loss is depending upon customers demand if company fulfill the demand of customers, it definitely gains profit if it do not fulfill need of their customers than it will gain loss. This dataset is uncleaned there are some missing values in the dataset. It contains character and numerical data type. We will use some method to clean our dataset to make it stronger and more valuable to perform different types of models to collect different results. We will also use predictive and descriptive analysis to discuss about how many customers received their products according to their demands and we will also find in which direction company sales trend moved upward or downward.

2 FILE - coding part
In initial step I Import 4 liabraries such as panda as pd for analys and manuplation, matplotlib.pyplot as plt for create the plot, seaborn as sns for visulization, numpy as np for mathematical operations. Thereafter I import my data set name as 'Sales dataset'. Afterthat we check the shape as well as duplicate values and null values in our dataset and also fill null value with 0. Afterthat we check the data summary. Aftherthat we check unique values and also rename some columns. We also check datatyp and convert object into category. Thereafter we do data visulization. Thereafter we balance our target variable. The next stage is modelling section in which we run some models. At last we create confusion matrix.
